{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Intro - "
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Lance Martin"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Preface - "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "These are notes I wrote for myself while studying for PhD qualifying exams at Stanford. \n",
      "\n",
      "I wanted to published them so that others could benefit.\n",
      "\n",
      "They draw from two sources:\n",
      "\n",
      "* CS229, an excellent machine learning class at Stanford taught by Andrew Ng.\n",
      "* An Introduction to Statistical Learning (ISL), an excellent text by G. James, D. Witten,  T. Hastie and R. Tibshirani (Springer, 2013).\n",
      "\n",
      "Some of the figures are taken from ISL with permission from the authors."
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Definition - "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Arthur Samuel on Machine learning from 1959: \n",
      "\n",
      "\"Field of study that gives computers the ability to learn without being explicitly programmed.\""
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Types of learning - "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Teach the computer how to do something. Apply this learning to new problems:\n",
      "\n",
      "* Classification problems\n",
      "* Reccomender systems\n",
      "* Identification of tumor type by expression profile\n",
      "\n",
      "The objective of supervised learning is to $learn$ a function, $h :x \\mapsto y $, so that $h(x)$ is a good predictor of $y$. \n",
      "\n",
      "$x$ is often used to denote the input variables (features) whereas $y$ is the output (target). \n",
      "\n",
      "For a simple regression problem: \n",
      "\n",
      "* 13 attributes of housing markets around Boston along with median house price. \n",
      "\n",
      "* It is possible to predict the price of a market given its attributes?\n",
      "\n",
      "First, we examine the target data - \n",
      "\n",
      "---\n",
      "\n",
      "Un-supervised learning - \n",
      "\n",
      "Let the computer learn how to do something, and use this to determine structure and patterns in data:\n",
      "\n",
      "* Clustering problems\n",
      "* Classifying sub-populations of single cells\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Basics - "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Given:\n",
      "\n",
      "* $X$, a set of measured features.\n",
      "* $Y$, a response.\n",
      "* Training data, a set of values ($X^1_i$ to $X^1_n$) for each $Y^1$.\n",
      "\n",
      "There exists some actual $f$ that captures the relationship between $Y$ and $X$.\n",
      "\n",
      "Statistical learning refers to a set of approaches for estimating $f$.\n",
      "\n",
      "$Y = f(X) + \\epsilon$\n",
      "\n",
      "* $Y$ is also a funtion of $\\epsilon$, which cannot be predicted with respect to $X$.\n",
      "* Irreducible error: Errors in our model due to $\\epsilon$ cannot be reduced using a different statistical learning model. \n",
      "* Reducible error: Errors in our model that can be reduced using a different statistical learning model. \n",
      "* Irreducible error will always provide an upper bound on the accuracy of our prediction for $Y$.\n",
      "\n",
      "---\n",
      "\n",
      "$F$:\n",
      "\n",
      "* Parameteric: Specify the form of $f$, with a set of pre-derfined paramters.\n",
      "* Non-Parameteric: No explicit assumptions about the functional form of $f$, fitting wider range of possible shapes for $f$.\n",
      "\n",
      "---\n",
      "\n",
      "$Y$:\n",
      "\n",
      "* Continuous: Regression methods for $f$ are used here.\n",
      "* Categorical: Classification methods for $f$ are used here.\n",
      "\n",
      "---\n",
      "\n",
      "Objectives:\n",
      "\n",
      "* Inference: How does $Y$ change with respect to difference values of $X$.\n",
      "* Prediction: Predict a value for $Y$ with respect to $X$.\n",
      "\n",
      "---\n",
      "\n",
      "Challenges:\n",
      "\n",
      "* Underfitting: Model does not recapituate features of true $f$. \n",
      "* Overfitting: Over-specified to the training data.\n",
      "* Interpretability: inference, this is often critical.\n",
      "\n",
      "---\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Test mean squared error is $T =$ Avg $(y_o - \\hat{f}(x_o))^2 = B^2 + V + var(\\epsilon)$\n",
      "\n",
      "This can be de-composed as the sum of:\n",
      "\n",
      "* Bias, $B$: Error introduced by using a model that is simple relative to actual relationship (e.g., under-fitting). \n",
      "* Variance, $V$: Amount by which $\\hat{f}$ would change if we estimated it using a different training data set (e.g., over-fitting).\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "De-bugging learning algorithms - "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Scenario:\n",
      "\n",
      "* Bayesian logistic regression has 20% test error.\n",
      "* Using 100 features (words).\n",
      "    \n",
      "Many common approaches:\n",
      "\n",
      "* Change size of feature set.\n",
      "* Change different algorithm.\n",
      "\n",
      "Usually one picks a method at random, which is not efficient.\n",
      "\n",
      "Better approach is to use diagnostics to understand why the algorithm is not working.\n",
      "\n",
      "Overfitting:\n",
      "\n",
      "* High variance.\n",
      "* Fitting high order polynomial to linear data.\n",
      "* In this case, training error will be much lower than test error. \n",
      "\n",
      "Underfitting:\n",
      "\n",
      "* High bias.\n",
      "* Fitting low order polynomial to complex data.\n",
      "* In this case, training error will also be high. \n",
      "\n",
      "To examine this, use a learning curve:\n",
      "\n",
      "* Plot both test and training error with respect to the training set size.\n",
      "* The test set error will usually go down as we increace the training set size.\n",
      "* The training error usually goes up with respect to m, the training set size.\n",
      "* It becomes harder to fit the model to more training examples well.\n",
      "\n",
      "Results:\n",
      "\n",
      "* Overfitting: A large gap between test and training is indicative of overfitting. To resolve, get more training data.\n",
      "* Underfitting: Test and training error are similarly poor. So, here want to get a different model in order to better fit our data.\n",
      "    \n",
      "In summary, these approaches should be used to address high variance (overfitting):\n",
      "\n",
      "* More training examples.\n",
      "* Smaller set of features.\n",
      "\n",
      "In summary, these approaches should be used to address high bias (underfitting):\n",
      "\n",
      "* Larger set of features.\n",
      "\n",
      "Objectives or cost functions:\n",
      "\n",
      "* We might have a business or scientific objective.\n",
      "* But, our algorithms have specific objectives (convex) functions. \n",
      "* We must ensure that this is a proper objective function to use.\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Approach - "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Start with simple learning systems:\n",
      "\n",
      "* It is hard to predict where a system will fail, a priori.\n",
      "\n",
      "The danger of over-theorizing:\n",
      "\n",
      "* Ensure your field of theoretical work is relevant to the application of interest."
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Include - "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cacm12-2.pdf"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}